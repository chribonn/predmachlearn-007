grep("$IL", colnames(adData))
colnames(adData)
grep("IL", colnames(adData))
adData[,grep("IL", colnames(adData))]
preProc <- preProcess(log10(training[,-grep("IL", colnames(adData))]+1), method="pca", pcaComp=2)
training[,-grep("IL", colnames(adData))]
preProc <- preProcess(log10(training[,-grep("IL", colnames(adData))]+1), method="pca", pcaComp=2)
log10(training[,-grep("IL", colnames(adData))]+1)
preProc <- preProcess(log10(training[,grep("IL", colnames(adData))]+1), method="pca", pcaComp=2)
?preProcess
IL_variables <- grep("^IL", names(training), value = TRUE)
preProc <- preProcess(training[, IL_variables], method = "pca", thresh = 0.9)
preProc <- preProcess(training[,grep("IL", colnames(adData))], method="pca", pcaComp=2)
preProc
preProc2 <- preProcess(training[, IL_variables], method = "pca", thresh = 0.9)
preProc2
preProc2 <- preProcess(training[, IL_variables], method = "pca", thresh = 0.8)
preProc2
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_variables <- grep("^IL", names(training), value = TRUE)
head(training)
modFit <- train(diagnosis ~ training[, IL_variables], method="glm", data=training)
training[, IL_variables]
modFit <- train(diagnosis ~ training[, IL_variables], method="glm", data=training)
featurePlot(x=training[, IL_variables], y=training$diagnosis, plot="pairs")
modFit <- train(diagnosis ~ IL_variables, method="glm", data=training)
modFit <- train(diagnosis ~ IL_variables, method="lm", data=training)
modFit <- train(diagnosis ~ training[,IL_variables], method="lm", data=training)
?train
IL_variables
chkData <- adData[,c(diagnosis, IL_variables)]
chkData <- adData[,c("diagnosis", IL_variables)]
modFit <- train(diagnosis ~ ., method="glm", data=chkData)
finMod <- modFit$finalModel
finMod
print(finMod)
modelFit1 <- train(chkData$diagnosis ~ ., method = "glm", preProcess="pca", data=chkData)
modelFit2 <- train(chkData$diagnosis ~ ., method = "glm", data=chkData)
modelFit1
modelFit2
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
predictors
diagnosis
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C1)
print(C2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training,
Control = trainControl(preProcOptions = list(thresh = 0.8)))
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C1)
print(C2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
# create a new DF of predictors and diagnosis
df <- data.frame(diagnosis, predictors_IL)
# create a training and testing set from this DF
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confusion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with PCA
modelFit <- train(training$diagnosis ~ ., method = "glm", data = training,
preProcess = "pca",
Control = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
?randomForest
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
?randomForest
a <- randomForest(y ~ ., data = vowel.train, importance = TRUE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.test, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, prox=TRUE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, prox=TRUE)
b <- varImp(a)
order(b, decreasing = FALSE)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, prox=TRUE)
b <- varImp(a)
order(b, decreasing = TRUE)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
# Then set the seed to 33833. Fit (1) a random forest predictor relating the
# factor variable y to the remaining variables and (2) a boosted predictor using
# the "gbm" method. Fit these both with the train() command in the caret package.
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# create models
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
# Then set the seed to 33833. Fit (1) a random forest predictor relating the
# factor variable y to the remaining variables and (2) a boosted predictor using
# the "gbm" method. Fit these both with the train() command in the caret package.
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# create models
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
# predict test
predict1 <- predict(fit1, newdata = vowel.test)
predict2 <- predict(fit2, newdata = vowel.test)
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
c1 <- confusionMatrix(predict1, vowel.test$y)
c2 <- confusionMatrix(predict2, vowel.test$y)
c3 <- confusionMatrix(predict3, DF_combined$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
# Set the seed to 62433 and predict diagnosis with all the other variables using
# a random forest ("rf"), boosted trees ("gbm") and linear discriminant analysis
# ("lda") model. Stack the predictions together using random forests ("rf").
# What is the resulting accuracy on the test set? Is it better or worse than
# each of the individual predictions?
set.seed(62433)
# create models
fit1 <- train(diagnosis ~ ., data = training, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(diagnosis ~ ., data = training, method = "gbm")
fit3 <- train(diagnosis ~ ., data = training, method = "lda")
# predict test
predict1 <- predict(fit1, newdata = testing)
predict2 <- predict(fit2, newdata = testing)
predict3 <- predict(fit3, newdata = testing)
# combine predictions
DF_combined <- data.frame(predict1, predict2, predict3, diagnosis = testing$diagnosis) # training$diagnosis?
fit_combined <- train(diagnosis ~ ., data = DF_combined, method = "rf")
predict4 <- predict(fit_combined, newdata = testing)
# confusion matrixes
c1 <- confusionMatrix(predict1, testing$diagnosis)
c2 <- confusionMatrix(predict2, testing$diagnosis)
c3 <- confusionMatrix(predict3, testing$diagnosis)
c4 <- confusionMatrix(predict4, testing$diagnosis)
print(paste(c1$overall[1], c2$overall[1], c3$overall[1], c4$overall[1]))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 325 and fit a support vector machine using the e1071 package
# to predict Compressive Strength using the default settings. Predict on the
# testing set. What is the RMSE?
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
?accuracy
library(forcast)
install.packages("forcast")
install.packages("forcast")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
# Set the seed to 325 and fit a support vector machine using the e1071 package
# to predict Compressive Strength using the default settings. Predict on the
# testing set. What is the RMSE?
set.seed(325)
library(e1071)
library(caret)
fit <- train(CompressiveStrength ~ ., data = training, method = "svmRadial")
prediction <- predict(fit, testing)
accuracy(prediction, testing$CompressiveStrength)
library(forecast)
accuracy(prediction, testing$CompressiveStrength)
setwd("E:/Data Science - John Hopkins University/08. Practical Machine Learning/predmachlearn-007")
load(file = fileRData)
fileRData <- "data/predmachlearn-007.RData"
load(file = fileRData)
print(paste0("Using data originally downloaded on the ", dateDownLoaded))
print(paste0("Using data originally downloaded on the ", dateDownloaded))
?read.csv
trainData
set.seed(123)
# load the libraries
library(caret)
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
is.na(belt)
is.na(trainData$belt)
is.na(trainData$roll_belt)
sum(is.na(trainData$roll_belt))
sum(is.na(trainData$yaw_forearm))
View(trainData)
View(trainData)
tmp <- trainData
threshold <- nrow(trainData) * 0.80
colsNA <- !apply(trainData, 2, function(x) sum(is.na(x)) > threshold)
colsNA <- apply(trainData, 2, function(x) sum(is.na(x)) > threshold)
head(trainData)
sum(is.na(trainData$var_accel_forearm))
threshold <- nrow(trainData) * 0.80
sum(is.na(trainData$var_accel_forearm)) > threshold
colsNA <- sapply(trainData, 2, function(x) sum(is.na(x)) > threshold)
colsNA <- apply(trainData, 2, function(x) { sum(is.na(x)) > threshold})
apply(trainData, 2, function(x) {sum(is.na(x))})
apply(trainData, 2, function(x) {sum(is.na(x)) > threshold})
a <- apply(trainData, 2, function(x) {sum(is.na(x)) > threshold})
a
colsNA
trainData <- trainData[, -colsNA]
trainData <- tmp
threshold <- nrow(trainData) * 0.80
colsNA <- apply(trainData, 2, function(x) { sum(is.na(x)) > threshold})
trainData <- trainData[, -colsNA]
trainData <- tmp
colsNA
colsNA <- sapply(trainData, function(x) { sum(is.na(x)) > threshold})
colsNA
trainData[, -colsNA]
trainData <- read.csv("data/pml-training.csv", na.strings=c("<NA>", "NA",""))
testData <- read.csv("data/pml-testing.csv", na.strings=c("<NA>", "NA",""))
save(dateDownloaded, trainData, testData, file = fileRData)
trainData<-trainData[, -(1:2)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
threshold <- nrow(trainData) * 0.80
colsNA <- sapply(trainData, function(x) { sum(is.na(x)) > threshold})
trainData[, -colsNA]
View(trainData)
View(trainData)
ncols(trainData[, -colsNA])
ncol(trainData[, -colsNA])
# load the training data
trainData <- read.csv("data/pml-training.csv", na.strings=c("<NA>", "NA",""))
# load the testing data
testData <- read.csv("data/pml-testing.csv", na.strings=c("<NA>", "NA",""))
# save the data to and R object. This ensures that if the source data is deleted or altered the results are reproducable.
save(dateDownloaded, trainData, testData, file = fileRData)
trainData<-trainData[, -(1:2)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
View(trainData)
View(trainData)
threshold <- nrow(trainData) * 0.80
colsNA <- sapply(trainData, function(x) { sum(is.na(x)) > threshold})
colsNA
trainData[, -colsNA]
sum(is.na(trainData$max_yaw_forearm))
threshold
trainData <- trainData[, -colsNA]
sum(is.na(trainData$max_yaw_forearm))
trainData <- trainData[-colsNA]
setwd("E:/Data Science - John Hopkins University/08. Practical Machine Learning/predmachlearn-007")
load(file = fileRData)
dateDownloaded <- date()
# load the training data
trainData <- read.csv("data/pml-training.csv", na.strings=c("<NA>", "NA",""))
# load the testing data
testData <- read.csv("data/pml-testing.csv", na.strings=c("<NA>", "NA",""))
# save the data to and R object. This ensures that if the source data is deleted or altered the results are reproducable.
save(dateDownloaded, trainData, testData, file = fileRData)
fileRData <- "data/predmachlearn-007.RData"
save(dateDownloaded, trainData, testData, file = fileRData)
trainData <- trainData[, -(1:2)]
traindata[sapply(x, function(x) !any(is.na(x)))]
trainData[sapply(trainData, function(x) !any(is.na(x)))]
threshold <- nrow(trainData) * 0.80
colsNA <- sapply(trainData, function(x) { sum(is.na(x)) > threshold})
trainData <- trainData[-colsNA]
trainData[sapply(trainData, function(x, threshold) sum(is.na(x)) < threshold)]
trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
fileRData <- "data/predmachlearn-007.RData"
load(file = fileRData)
trainData <- trainData[, -(1:2)]
threshold <- nrow(trainData) * 0.80
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
View(trainData)
View(trainData)
fileRData <- "data/predmachlearn-007.RData"
load(file = fileRData)
set.seed(123)
# load the libraries
library(caret)
trainData <- trainData[, -(1:6)]
View(trainData)
View(trainData)
threshold <- nrow(trainData) * 0.80
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
View(trainData)
View(trainData)
load(file = fileRData)
trainData <- trainData[, -(1:6)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
threshold <- nrow(trainData) * 0.80
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
rfDataFit <- randomForest(classe ~. , data = trainData)
library(randoForest)
library(randomForest)
rfDataFit <- randomForest(classe ~ . , data = trainData)
load(file = fileRData)
trainData <- trainData[, -(1:6)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
threshold <- nrow(trainData) * 0.90
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
threshold <- nrow(trainData) * 0.60
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
threshold <- nrow(trainData) * 0.95
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
modFit <- train(classe ~ ., data=trainData, method="rf")
str(trainData$classe)
library(parallel)
library(doParallel)
install.packages("parallel")
install.packages("parallel")
library(parallel)
library(doParallel)
library(doParallel)
install.packages("doParallel")
library(doParallel)
?trainCotrols
fileRData <- "data/predmachlearn-007.RData"
load(file = fileRData)
# set the seed for reproducability
set.seed(123)
# load the libraries
library(caret)
library(randomForest)
trainData <- trainData[, -(1:6)]
nzv <- nearZeroVar(trainData)
trainData <- trainData[, -nzv]
threshold <- nrow(trainData) * 0.80
trainData <- trainData[sapply(trainData, function(x) sum(is.na(x)) < threshold)]
inTrain <- createDataPartition(y = trainData$classe, p = 0.7, list = FALSE)
trainData.train <- trainData[inTrain, ]
trainData.crossval <- trainData[-inTrain, ]
model <- randomForest(classe ~ ., data = trainData.train)
model
predict.crossval <- predict(model, trainData.crossval)
confusionMatrix(trainData.crossval$classe, predict.crossval)
predictTest <- predict(model, testData)
predictTest
View(trainData)
View(trainData)
